{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs2QWTzNGuN1BQJVHr+3EI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paritosh-Shukla24/Autogen_Agents/blob/main/Autogen_coding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqv6vlU9LWxa",
        "outputId": "7db3f105-7d4c-401d-a817-8361b814f539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen-agentchat~=0.2\n",
            "  Downloading autogen_agentchat-0.2.40-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting diskcache (from autogen-agentchat~=0.2)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from autogen-agentchat~=0.2)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from autogen-agentchat~=0.2)\n",
            "  Downloading FLAML-2.3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (1.57.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (24.2)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (2.10.3)\n",
            "Collecting python-dotenv (from autogen-agentchat~=0.2)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (2.5.0)\n",
            "Collecting tiktoken (from autogen-agentchat~=0.2)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->autogen-agentchat~=0.2) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->autogen-agentchat~=0.2) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->autogen-agentchat~=0.2) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tavily-python) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->autogen-agentchat~=0.2) (1.2.2)\n",
            "Downloading autogen_agentchat-0.2.40-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.3/382.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.3-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.2/314.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, flaml, diskcache, tiktoken, docker, tavily-python, autogen-agentchat\n",
            "Successfully installed autogen-agentchat-0.2.40 diskcache-5.6.3 docker-7.1.0 flaml-2.3.3 python-dotenv-1.0.1 tavily-python-0.5.0 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "! pip install \"autogen-agentchat~=0.2\" \"tavily-python\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dask[dataframe]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez-w4HrKL4E5",
        "outputId": "5f36f8a2-9c13-4c32-effb-80e9a1cb2541"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
            "  Downloading dask_expr-1.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.21.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.17.0)\n",
            "Downloading dask_expr-1.1.16-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dask-expr\n",
            "Successfully installed dask-expr-1.1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE43ElHJMGRO",
        "outputId": "e12953af-5cdb-4227-cac1-6a17fc5d0620"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.5-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.1-py3-none-any.whl (605 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.5/605.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.5-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=5cf450de8a18e31886ccbd6cab17683f8cd328659597ba4c52626a7be4eaf467\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.1 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.7.5 protobuf-5.29.2 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from typing import Annotated\n",
        "\n",
        "from tavily import TavilyClient\n",
        "\n",
        "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json, register_function\n",
        "from autogen.agentchat.contrib.capabilities import teachability\n",
        "from autogen.cache import Cache\n",
        "from autogen.coding import DockerCommandLineCodeExecutor, LocalCommandLineCodeExecutor\n",
        "from google.colab import userdata\n",
        "api_key=userdata.get('OPENAI_API_KEY')\n",
        "config_list = [\n",
        "    {\"model\": \"gpt-4\", \"api_key\":api_key},\n",
        "    {\"model\": \"gpt-3.5-turbo\", \"api_key\": api_key},\n",
        "]\n",
        "# You can also use the following method to load the config list from a file or environment variable.\n",
        "# config_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")"
      ],
      "metadata": {
        "id": "fgMN4hs-Lbc7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tavily = TavilyClient(api_key=userdata.get('TAVILY_API_KEY') )\n",
        "\n",
        "\n",
        "def search_tool(query: Annotated[str, \"The search query\"]) -> Annotated[str, \"The search results\"]:\n",
        "    return tavily.get_search_context(query=query, search_depth=\"advanced\")"
      ],
      "metadata": {
        "id": "CLwNLaiOLhxu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: this ReAct prompt is adapted from Langchain's ReAct agent: https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L79\n",
        "ReAct_prompt = \"\"\"\n",
        "Answer the following questions as best you can. You have access to tools provided.\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this process can repeat multiple times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "Question: {input}\n",
        "\"\"\"\n",
        "\n",
        "# Define the ReAct prompt message. Assuming a \"question\" field is present in the context\n",
        "\n",
        "\n",
        "def react_prompt_message(sender, recipient, context):\n",
        "    return ReAct_prompt.format(input=context[\"question\"])"
      ],
      "metadata": {
        "id": "XrngrOqlNAuY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up code executor.\n",
        "os.makedirs(\"coding\", exist_ok=True)\n",
        "# Use docker executor for running code in a container if you have docker installed.\n",
        "# code_executor = DockerCommandLineCodeExecutor(work_dir=\"coding\")\n",
        "code_executor = LocalCommandLineCodeExecutor(work_dir=\"coding\")\n",
        "\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"User\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    human_input_mode=\"ALWAYS\",\n",
        "    max_consecutive_auto_reply=10,\n",
        "    code_execution_config={\"executor\": code_executor},\n",
        ")\n",
        "\n",
        "assistant = AssistantAgent(\n",
        "    name=\"Assistant\",\n",
        "    system_message=\"Only use the tools you have been provided with. Reply TERMINATE when the task is done.\",\n",
        "    llm_config={\"config_list\": config_list, \"cache_seed\": None},\n",
        ")\n",
        "\n",
        "# Register the search tool.\n",
        "register_function(\n",
        "    search_tool,\n",
        "    caller=assistant,\n",
        "    executor=user_proxy,\n",
        "    name=\"search_tool\",\n",
        "    description=\"Search the web for the given query\",\n",
        ")\n",
        "\n",
        "# Cache LLM responses. To get different responses, change the cache_seed value.\n",
        "with Cache.disk(cache_seed=43) as cache:\n",
        "    user_proxy.initiate_chat(\n",
        "        assistant,\n",
        "        message=react_prompt_message,\n",
        "        question=\"What is the result of super bowl 2024?\",\n",
        "        cache=cache,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyH4FEkRNE7a",
        "outputId": "b35c9ca3-f9c5-453b-8f8b-0bcb61b1158b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User (to Assistant):\n",
            "\n",
            "\n",
            "Answer the following questions as best you can. You have access to tools provided.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this process can repeat multiple times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "Question: What is the result of super bowl 2024?\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to User):\n",
            "\n",
            "Thought: I don't have this information. I will use the search tool to find the result of super bowl 2024.\n",
            "Action: Use the search tool to find the required information.\n",
            "Action Input: {\"query\": \"Super Bowl 2024 result\"}\n",
            "***** Suggested tool call (call_M6qaOmDhMECZSkB3MGotp2gr): search_tool *****\n",
            "Arguments: \n",
            "\n",
            "{\n",
            "  \"query\": \"Super Bowl 2024 result\"\n",
            "}\n",
            "****************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as User. Provide feedback to Assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION search_tool...\n",
            "User (to Assistant):\n",
            "\n",
            "User (to Assistant):\n",
            "\n",
            "***** Response from calling tool (call_M6qaOmDhMECZSkB3MGotp2gr) *****\n",
            "\"[\\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.espn.com/nfl/game/_/gameId/401547378/49ers-chiefs\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Chiefs 25-22 49ers (Feb 11, 2024) Final Score - ESPN ESPN Purdy 23/38, 255 YDS, 1 TD KC ### P. McCaffrey 8 REC, 80 YDS, 1 TD KC ### T. Patrick Mahomes rallies the Chiefs to second straight Super Bowl title, 25-22 over 49ers in overtime ---------------------------------------------------------------------------------------------------- \\\\\\\\u2014 Patrick Mahomes, Travis Kelce and Andy Reid have made the Kansas City Chiefs a dynasty. Marquez Valdes-Scantling Pass From Patrick Mahomes for 16 Yds Harrison Butker Made Ex. Pt Jauan Jennings Pass From Brock Purdy for 10 Yds, J.Moody extra point is Blocked (L.Chenal), ATTEMPT FAILS. Mecole Hardman Jr. Pass From Patrick Mahomes for 3 Yds ESPN BET is available in states where PENN is licensed to offer sports wagering.\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://apnews.com/article/super-bowl-2024-score-chiefs-49ers-49b5dca51c05ab0f259cef0d7da76c2d\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"(AP Photo/David J. Phillip)\\\\\\\\nKansas City Chiefs quarterback Patrick Mahomes (15) celebrates after throwing the game-winning touchdown pass to wide receiver Mecole Hardman Jr. during the overtime of the NFL Super Bowl 58 football game against the San Francisco 49ers Sunday, Feb. 11, 2024, in Las Vegas. (AP Photo/David J. Phillip)\\\\\\\\nKansas City Chiefs quarterback Patrick Mahomes (15) celebrates after throwing the game-winning touchdown pass to wide receiver Mecole Hardman Jr. during the overtime of the NFL Super Bowl 58 football game against the San Francisco 49ers Sunday, Feb. 11, 2024, in Las Vegas. (AP Photo/George Walker IV)\\\\\\\\nSan Francisco 49ers running back Christian McCaffrey (23) runs into the end zone for a topuchdown against the Kansas City Chiefs during the first half of the NFL Super Bowl 58 football game Sunday, Feb. 11, 2024, in Las Vegas. (AP Photo/George Walker IV)\\\\\\\\nSan Francisco 49ers running back Christian McCaffrey (23) runs into the end zone for a topuchdown against the Kansas City Chiefs during the first half of the NFL Super Bowl 58 football game Sunday, Feb. 11, 2024, in Las Vegas. Patrick Mahomes rallies the Chiefs to second straight Super Bowl title, 25-22 over 49ers in overtime\\\\\\\\nThe Kansas City Chiefs beat the San Francisco 49ers 25-22 in overtime in the Super Bowl in Las Vegas on Sunday night.\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.foxsports.com/nfl-super-bowl-winners-and-results\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Super Bowl Wins by Team ; New England Patriots, 6 ; Pittsburgh Steelers, 6 ; Dallas Cowboys, 5 ; San Francisco 49ers, 5.\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.nbcnews.com/news/sports/live-blog/super-bowl-chiefs-49ers-score-live-updates-rcna136833\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Profile\\\\\\\\nSections\\\\\\\\ntv\\\\\\\\nFeatured\\\\\\\\nMore From NBC\\\\\\\\nFollow NBC News\\\\\\\\nnews Alerts\\\\\\\\nThere are no new alerts at this time\\\\\\\\nSuper Bowl LVIII\\\\\\\\nSuper Bowl 2024 live updates: 49ers vs. Chiefs how to watch, kickoff time, pregame, Taylor Swift arrival\\\\\\\\nEverything you need to know about Super Bowl 58:\\\\\\\\nJason Abbruzzese\\\\\\\\nAnd we're under way. \\\\\\\\u201cDespite the 12-hour flight and 17-hour time difference, the Embassy can confidently Speak Now to say that if she departs Tokyo in the evening after her concert, she should comfortably arrive in Las Vegas before the Super Bowl begins.\\\\\\\\u201d\\\\\\\\nNBC News\\\\\\\\nFootball fans across the country were celebrating after they were surprised with tickets to the Super Bowl in Las Vegas. Mahomes warms up\\\\\\\\nNBC News\\\\\\\\nICYMI: A person tried to climb the Vegas Sphere (and got arrested)\\\\\\\\nSaba Hamedy\\\\\\\\nLas Vegas police confirmed last Wednesday that a man was arrested after he climbed a structure on the 200 block of Sands Avenue, where the Sphere is located.\\\\\\\\n President Biden is skipping a Super Bowl interview\\\\\\\\nMonica Alba\\\\\\\\nJonathan Allen\\\\\\\\nFor the second year in a row, President Joe Biden is passing on the opportunity to sit down for a Super Bowl interview that could reach millions of Americans on Sunday \\\\\\\\u2014 a move his advisers say is part of their larger communication strategy.\\\\\\\\n Can the Niners tie the Patriots and Steelers?\\\\\\\\nClaire Cardona\\\\\\\\nAllan Smith\\\\\\\\nThe Kansas City Chiefs, the reigning Super Bowl champs, could go two in a row if they beat the San Francisco 49ers.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://en.wikipedia.org/wiki/Super_Bowl_LVIII\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"The new process no longer allows cities to bid for the game; the league now chooses the potential candidates.[3]\\\\\\\\nIn March 2020, the league and the NFLPA agreed to expand the regular season from 16 to 17 games beginning in 2021, pushing Super Bowl LVIII to February 11, 2024, and causing a conflict with New Orleans' Mardi Gras celebrations.[6] The league formally announced on October 14, 2020, that New Orleans would host Super Bowl LIX instead of Super Bowl LVIII,[7] and then announced on December 15, 2021, that Las Vegas was chosen as the new site.[8]\\\\\\\\nLogo\\\\\\\\nThe official logo was unveiled on February 13, 2023; it follows the updated logo template introduced by Super Bowl LVI, with the traditional Roman numerals featuring imagery reflecting the host city/region (in this case, the skyline of the Las Vegas Strip and the Las Vegas sign). The game will be televised nationally by CBS, streamed on Paramount+, alternatively broadcast on youth-oriented sister network Nickelodeon, and, for the first time, televised on the Spanish-language network Univision.[4] It will also be the second simulcast in Super Bowl history, the first being Super Bowl I.[5]\\\\\\\\nBackground\\\\\\\\nHost selection\\\\\\\\nOn May 23, 2018, the league initially selected New Orleans as the site for Super Bowl LVIII. The numbers in parentheses below indicate their uniform numbers.[1]\\\\\\\\nSuper Bowl LVIII is the third assignment for Vinovich as referee of the national championship game, while Perlman and Hill will officiate their final games after careers spanning 23 and 25 years, respectively.[1] Killens, a former NFL linebacker, will become the first person in history to officiate a Super Bowl after having played in one (Super Bowl XXXIV in 2000, for the Tennessee Titans).[31]\\\\\\\\nReferences\\\\\\\\nExternal links Also as part of the pregame festivities, rapper Post Malone will perform \\\\\\\\\\\\\\\"America the Beautiful\\\\\\\\\\\\\\\" and contemporary R&B singer Andra Day will perform \\\\\\\\\\\\\\\"Lift Every Voice and Sing\\\\\\\\\\\\\\\", with actress Anjel Pi\\\\\\\\u00f1ero performing both songs in ASL.[29]\\\\\\\\nHalftime\\\\\\\\nOn September 24, 2023, it was announced that American R&B singer Usher will headline the Super Bowl LVIII Halftime Show.[30]\\\\\\\\nGame summary\\\\\\\\nBox score\\\\\\\\nat Allegiant Stadium, Paradise, Nevada\\\\\\\\nOfficials\\\\\\\\nSuper Bowl LVIII will feature seven officials, a replay official, a replay assistant, and eight alternate officials. TelevisaUnivision announced during its upfronts in May 2023 that it had reached an agreement with CBS to carry Super Bowl LVIII on Univision.[16][17][18]\\\\\\\\nThe game will be available to stream on Paramount+ in English, on TelevisaUnivision's Vix in Spanish,[19] and similar to the prior year for free on mobile devices and the web on the NFL app and NFL.com, in addition to the paid NFL+ app.[20]\\\\\\\\n\\\\\\\"}\\\"]\"\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to User):\n",
            "\n",
            "Observation: The search tool results show that the Kansas City Chiefs won the Super Bowl 2024 against the San Francisco 49ers with a score of 25-22 in overtime.\n",
            "Thought: I now know the final answer.\n",
            "Final Answer: The Kansas City Chiefs won the Super Bowl 2024 against the San Francisco 49ers with a score of 25-22.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as User. Provide feedback to Assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "User (to Assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Assistant (to User):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as User. Provide feedback to Assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
        "from autogen.cache import Cache\n",
        "from autogen.coding import DockerCommandLineCodeExecutor, LocalCommandLineCodeExecutor\n",
        "\n",
        "config_list = [\n",
        "    {\"model\": \"gpt-4-1106-preview\", \"api_key\": userdata.get('OPENAI_API_KEY')},\n",
        "    {\"model\": \"gpt-3.5-turbo\", \"api_key\": userdata.get('OPENAI_API_KEY')},\n",
        "]\n",
        "# You can also use the following method to load the config list from a file or environment variable.\n",
        "# config_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")\n",
        "os.makedirs(\"coding\", exist_ok=True)\n",
        "# Use DockerCommandLineCodeExecutor if docker is available to run the generated code.\n",
        "# Using docker is safer than running the generated code directly.\n",
        "# code_executor = DockerCommandLineCodeExecutor(work_dir=\"coding\")\n",
        "code_executor = LocalCommandLineCodeExecutor(work_dir=\"coding\")\n",
        "\n",
        "user_proxy = UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    human_input_mode=\"TERMINATE\",\n",
        "    max_consecutive_auto_reply=10,\n",
        "    code_execution_config={\"executor\": code_executor},\n",
        ")\n",
        "\n",
        "writing_assistant = AssistantAgent(\n",
        "    name=\"writing_assistant\",\n",
        "    system_message=\"You are an writing assistant tasked to write engaging blogpost. You try generate the best blogpost possible for the user's request. If the user provides critique, respond with a revised version of your previous attempts.\",\n",
        "    llm_config={\"config_list\": config_list, \"cache_seed\": None},\n",
        ")\n",
        "\n",
        "reflection_assistant = AssistantAgent(\n",
        "    name=\"reflection_assistant\",\n",
        "    system_message=\"Generate critique and recommendations on the writing. Provide detailed recommendations, including requests for length, depth, style, etc..\",\n",
        "    llm_config={\"config_list\": config_list, \"cache_seed\": None},\n",
        ")"
      ],
      "metadata": {
        "id": "SZyd9Bk5Qq-i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reflection_message(recipient, messages, sender, config):\n",
        "    print(\"Reflecting...\")\n",
        "    return f\"Reflect and provide critique on the following writing. \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\n",
        "\n",
        "\n",
        "nested_chat_queue = [\n",
        "    {\n",
        "        \"recipient\": reflection_assistant,\n",
        "        \"message\": reflection_message,\n",
        "        \"max_turns\": 1,\n",
        "    },\n",
        "]\n",
        "user_proxy.register_nested_chats(\n",
        "    nested_chat_queue,\n",
        "    trigger=writing_assistant,\n",
        "    # position=4,\n",
        ")\n",
        "\n",
        "# Use Cache.disk to cache the generated responses.\n",
        "# This is useful when the same request to the LLM is made multiple times.\n",
        "with Cache.disk(cache_seed=42) as cache:\n",
        "    user_proxy.initiate_chat(\n",
        "        writing_assistant,\n",
        "        message=\"Write an engaging blogpost on the recent updates in AI. \"\n",
        "        \"The blogpost should be engaging and understandable for general audience. \"\n",
        "        \"Should have more than 3 paragraphes but no longer than 1000 words.\",\n",
        "        max_turns=2,\n",
        "        cache=cache,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDMDnCASNJg5",
        "outputId": "c67aaf50-f6c8-498e-a358-66429d62ac0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to writing_assistant):\n",
            "\n",
            "Write an engaging blogpost on the recent updates in AI. The blogpost should be engaging and understandable for general audience. Should have more than 3 paragraphes but no longer than 1000 words.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "writing_assistant (to user_proxy):\n",
            "\n",
            "### Embracing the Future: A Glimpse into the Latest Advances in AI\n",
            "\n",
            "Artificial Intelligence (AI) continues to transform our lives, weaving its way into the fabric of our daily experiences. From algorithms that predict what we'll buy next, to virtual assistants that understand our speech better than ever, AI is not just a buzzword—it's an increasingly sophisticated set of technologies that is changing the game in every sector. In this engaging exploration, we'll dive into the recent updates in AI that are setting the stage for a future that's more interconnected and intelligent than we've ever imagined.\n",
            "\n",
            "#### Understanding the Human Touch in AI\n",
            "\n",
            "One of the most exciting updates in the world of AI is the advancements in natural language processing (NLP). Just think about the last time you asked Siri for directions or told Alexa to play your favorite tune. That seamless interaction? It's powered by NLP. But it's not just about understanding words; AI is now grasping the nuances of human language—sarcasm, humor, and even regional dialects. This leap forward is due to improved machine learning models and the incorporation of vast amounts of linguistic data. These advancements mean that AI is better equipped to assist, engage, and even empathize with users, bridging the gap between human and machine interaction.\n",
            "\n",
            "#### AI and the Healthcare Revolution\n",
            "\n",
            "If there's one industry that's poised for a radical change thanks to AI, it's healthcare. Recent innovations have led to AI systems that can predict patient outcomes, tailor treatments, and even assist in complex surgeries. AI-driven diagnostic tools are becoming more precise, leading to earlier and more accurate detections of diseases such as cancer. One breakthrough to highlight is the development of algorithms that can scan medical images, such as MRIs and X-rays, to detect abnormalities with a level of precision that matches—and sometimes surpasses—the trained eye of radiologists. This isn't just about robots replacing doctors, but about AI empowering healthcare professionals with tools that offer new insights and efficiencies.\n",
            "\n",
            "#### Revolutionizing Everyday Life\n",
            "\n",
            "It's not all about grand innovations in the lab or hospital; AI is revolutionizing our everyday lives too. In the realm of personal technology, smartphones are getting smarter, with AI algorithms optimizing battery life, managing our appointments, and even tailoring our newsfeeds to suit our interests. In the home, smart thermostats learn our preferences and adjust the temperature accordingly, reducing energy consumption and our bills. In the transportation sector, AI is leading the way towards self-driving cars, with recent updates improving their ability to navigate complex urban environments safely.\n",
            "\n",
            "But perhaps the most immediate impact of AI is in the way it's fostering a personalized experience—be it in shopping, content consumption, or education. Algorithms analyze our behavior to provide recommendations that feel uniquely suited to our tastes and needs. This level of personalization is no small feat; it represents a profound shift in how we interact with technology, turning our devices from mere tools into proactive personal assistants that understand us.\n",
            "\n",
            "#### Ethical Considerations and Future Outlook\n",
            "\n",
            "With these incredible advancements come important ethical considerations. As AI becomes more integrated into our lives, questions around privacy, data security, and the potential for bias in AI systems become increasingly pressing. The future of AI is not just about creating more advanced technologies but ensuring that these technologies are used responsibly. As we stand on the cusp of a new era of AI, one thing is clear: the need for open discussions about the direction and implications of these formidable tools is paramount.\n",
            "\n",
            "As we look ahead, AI is set to become an even more integral part of our world. From enhancing our abilities to solve complex problems to improving our quality of life, the potential is limitless. These recent updates in AI are not just incremental steps; they're giant leaps in our ongoing quest to push the boundaries of what's possible. And as we venture into this brave new world, it is our collective curiosity, creativity, and caution that will ensure AI serves to enrich human potential, not overshadow it.\n",
            "\n",
            "Stay tuned, because if one thing's for certain, it's that the AI revolution is only just beginning.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "Reflecting...\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "user_proxy (to reflection_assistant):\n",
            "\n",
            "Reflect and provide critique on the following writing. \n",
            "\n",
            " ### Embracing the Future: A Glimpse into the Latest Advances in AI\n",
            "\n",
            "Artificial Intelligence (AI) continues to transform our lives, weaving its way into the fabric of our daily experiences. From algorithms that predict what we'll buy next, to virtual assistants that understand our speech better than ever, AI is not just a buzzword—it's an increasingly sophisticated set of technologies that is changing the game in every sector. In this engaging exploration, we'll dive into the recent updates in AI that are setting the stage for a future that's more interconnected and intelligent than we've ever imagined.\n",
            "\n",
            "#### Understanding the Human Touch in AI\n",
            "\n",
            "One of the most exciting updates in the world of AI is the advancements in natural language processing (NLP). Just think about the last time you asked Siri for directions or told Alexa to play your favorite tune. That seamless interaction? It's powered by NLP. But it's not just about understanding words; AI is now grasping the nuances of human language—sarcasm, humor, and even regional dialects. This leap forward is due to improved machine learning models and the incorporation of vast amounts of linguistic data. These advancements mean that AI is better equipped to assist, engage, and even empathize with users, bridging the gap between human and machine interaction.\n",
            "\n",
            "#### AI and the Healthcare Revolution\n",
            "\n",
            "If there's one industry that's poised for a radical change thanks to AI, it's healthcare. Recent innovations have led to AI systems that can predict patient outcomes, tailor treatments, and even assist in complex surgeries. AI-driven diagnostic tools are becoming more precise, leading to earlier and more accurate detections of diseases such as cancer. One breakthrough to highlight is the development of algorithms that can scan medical images, such as MRIs and X-rays, to detect abnormalities with a level of precision that matches—and sometimes surpasses—the trained eye of radiologists. This isn't just about robots replacing doctors, but about AI empowering healthcare professionals with tools that offer new insights and efficiencies.\n",
            "\n",
            "#### Revolutionizing Everyday Life\n",
            "\n",
            "It's not all about grand innovations in the lab or hospital; AI is revolutionizing our everyday lives too. In the realm of personal technology, smartphones are getting smarter, with AI algorithms optimizing battery life, managing our appointments, and even tailoring our newsfeeds to suit our interests. In the home, smart thermostats learn our preferences and adjust the temperature accordingly, reducing energy consumption and our bills. In the transportation sector, AI is leading the way towards self-driving cars, with recent updates improving their ability to navigate complex urban environments safely.\n",
            "\n",
            "But perhaps the most immediate impact of AI is in the way it's fostering a personalized experience—be it in shopping, content consumption, or education. Algorithms analyze our behavior to provide recommendations that feel uniquely suited to our tastes and needs. This level of personalization is no small feat; it represents a profound shift in how we interact with technology, turning our devices from mere tools into proactive personal assistants that understand us.\n",
            "\n",
            "#### Ethical Considerations and Future Outlook\n",
            "\n",
            "With these incredible advancements come important ethical considerations. As AI becomes more integrated into our lives, questions around privacy, data security, and the potential for bias in AI systems become increasingly pressing. The future of AI is not just about creating more advanced technologies but ensuring that these technologies are used responsibly. As we stand on the cusp of a new era of AI, one thing is clear: the need for open discussions about the direction and implications of these formidable tools is paramount.\n",
            "\n",
            "As we look ahead, AI is set to become an even more integral part of our world. From enhancing our abilities to solve complex problems to improving our quality of life, the potential is limitless. These recent updates in AI are not just incremental steps; they're giant leaps in our ongoing quest to push the boundaries of what's possible. And as we venture into this brave new world, it is our collective curiosity, creativity, and caution that will ensure AI serves to enrich human potential, not overshadow it.\n",
            "\n",
            "Stay tuned, because if one thing's for certain, it's that the AI revolution is only just beginning.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "reflection_assistant (to user_proxy):\n",
            "\n",
            "The provided piece, \"Embracing the Future: A Glimpse into the Latest Advances in AI,\" is an informative and engaging article structured around the significant impact of artificial intelligence in different sectors. Here's a critique of the writing followed by recommendations:\n",
            "\n",
            "### Critique:\n",
            "\n",
            "1. **Introduction:** The piece begins with a strong and inviting introduction, effectively setting the stage for a discussion on AI and its role in contemporary society. It captures the reader's attention and piques interest in the subject.\n",
            "\n",
            "2. **Language and Style:** The writing is clear, concise, and accessible to a broad audience, which is commendable. It maintains a balance between technical detail and readability.\n",
            "\n",
            "3. **Content and Depth:** The article provides a survey of several applications of AI but does not dive deeply into any single topic. It mentions the advancements in NLP, healthcare, everyday technology, and personalization, which is adequate for a general audience but may lack sufficient depth for readers seeking more comprehensive insight into AI's advancements. \n",
            "\n",
            "4. **Organization:** The organization of the content is logical, flowing nicely from one application of AI to the next while maintaining thematic coherence.\n",
            "\n",
            "5. **Examples and Anecdotes:** The writing includes relevant examples, like Siri and Alexa illustrating NLP, which helps ground the discussion in tangible experiences for the reader. However, it could benefit from more specific case studies or anecdotes to provide depth and evidence for some of the claims made.\n",
            "\n",
            "6. **Ethical Considerations:** The section on ethical considerations is necessary and appreciated. However, the discussion here feels somewhat generalized and could be strengthened with specific examples or potential solutions to the problems posed.\n",
            "\n",
            "7. **Conclusion:** The conclusion is forward-looking and maintains a positive tone regarding the future of AI. It successfully reiterates the main themes of the article but may seem a tad repetitive.\n",
            "\n",
            "### Recommendations:\n",
            "\n",
            "- **Depth:** Offer a deeper exploration of at least one AI advancement area. For instance, detailing how AI-driven diagnostic tools have evolved could provide readers with a more thorough understanding of AI's capabilities.\n",
            "\n",
            "- **Length:** The current scope is appropriate for an overview, but a longer piece, approximately 1,500–2,000 words, would allow for more detailed discussions on each topic.\n",
            "\n",
            "- **Case Studies:** Introduce detailed case studies that exemplify the advances in AI. This would not only lend credibility to the claims but also provide a narrative for the reader to follow.\n",
            "\n",
            "- **Ethical Considerations:** Devote a separate, more detailed section to ethical considerations. Include recent debates, policy discussions, or examples of ethical AI frameworks being developed.\n",
            "\n",
            "- **Visual Elements:** Incorporate charts, infographics, or images to illustrate advancements or statistics in AI, enhancing reader engagement and comprehension.\n",
            "\n",
            "- **Future Predictions:** Bolster the future outlook section with potential upcoming trends or technologies in AI, possibly based on recent research or expert predictions. \n",
            "\n",
            "- **Style:** While the writing style is engaging, injecting additional personality or anecdotes could provide an even more compelling read. A touch of humor or first-person narrative can create a more direct connection with the reader.\n",
            "\n",
            "- **References:** Include references or further reading suggestions for readers interested in exploring specific topics in more depth.\n",
            "\n",
            "By increasing the depth, providing more tangible examples, and expanding the discussion on ethical implications, the article could grow into a comprehensive resource for readers curious about AI's role in modern society and its future potential.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "user_proxy (to writing_assistant):\n",
            "\n",
            "The provided piece, \"Embracing the Future: A Glimpse into the Latest Advances in AI,\" is an informative and engaging article structured around the significant impact of artificial intelligence in different sectors. Here's a critique of the writing followed by recommendations:\n",
            "\n",
            "### Critique:\n",
            "\n",
            "1. **Introduction:** The piece begins with a strong and inviting introduction, effectively setting the stage for a discussion on AI and its role in contemporary society. It captures the reader's attention and piques interest in the subject.\n",
            "\n",
            "2. **Language and Style:** The writing is clear, concise, and accessible to a broad audience, which is commendable. It maintains a balance between technical detail and readability.\n",
            "\n",
            "3. **Content and Depth:** The article provides a survey of several applications of AI but does not dive deeply into any single topic. It mentions the advancements in NLP, healthcare, everyday technology, and personalization, which is adequate for a general audience but may lack sufficient depth for readers seeking more comprehensive insight into AI's advancements. \n",
            "\n",
            "4. **Organization:** The organization of the content is logical, flowing nicely from one application of AI to the next while maintaining thematic coherence.\n",
            "\n",
            "5. **Examples and Anecdotes:** The writing includes relevant examples, like Siri and Alexa illustrating NLP, which helps ground the discussion in tangible experiences for the reader. However, it could benefit from more specific case studies or anecdotes to provide depth and evidence for some of the claims made.\n",
            "\n",
            "6. **Ethical Considerations:** The section on ethical considerations is necessary and appreciated. However, the discussion here feels somewhat generalized and could be strengthened with specific examples or potential solutions to the problems posed.\n",
            "\n",
            "7. **Conclusion:** The conclusion is forward-looking and maintains a positive tone regarding the future of AI. It successfully reiterates the main themes of the article but may seem a tad repetitive.\n",
            "\n",
            "### Recommendations:\n",
            "\n",
            "- **Depth:** Offer a deeper exploration of at least one AI advancement area. For instance, detailing how AI-driven diagnostic tools have evolved could provide readers with a more thorough understanding of AI's capabilities.\n",
            "\n",
            "- **Length:** The current scope is appropriate for an overview, but a longer piece, approximately 1,500–2,000 words, would allow for more detailed discussions on each topic.\n",
            "\n",
            "- **Case Studies:** Introduce detailed case studies that exemplify the advances in AI. This would not only lend credibility to the claims but also provide a narrative for the reader to follow.\n",
            "\n",
            "- **Ethical Considerations:** Devote a separate, more detailed section to ethical considerations. Include recent debates, policy discussions, or examples of ethical AI frameworks being developed.\n",
            "\n",
            "- **Visual Elements:** Incorporate charts, infographics, or images to illustrate advancements or statistics in AI, enhancing reader engagement and comprehension.\n",
            "\n",
            "- **Future Predictions:** Bolster the future outlook section with potential upcoming trends or technologies in AI, possibly based on recent research or expert predictions. \n",
            "\n",
            "- **Style:** While the writing style is engaging, injecting additional personality or anecdotes could provide an even more compelling read. A touch of humor or first-person narrative can create a more direct connection with the reader.\n",
            "\n",
            "- **References:** Include references or further reading suggestions for readers interested in exploring specific topics in more depth.\n",
            "\n",
            "By increasing the depth, providing more tangible examples, and expanding the discussion on ethical implications, the article could grow into a comprehensive resource for readers curious about AI's role in modern society and its future potential.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "writing_assistant (to user_proxy):\n",
            "\n",
            "### Decoding AI: Unveiling the Breakthroughs that Are Redefining Our World\n",
            "\n",
            "Artificial intelligence (AI) isn't just a plot point in science fiction anymore; it's a reality that's reshaping our world in incredible ways. With each passing day, AI becomes more sophisticated, more accessible, and more integral to our daily lives. In this dive into the heart of contemporary AI advancements, we'll unwrap the layers of this complex field to reveal how it's impacting various aspects of society, focus on a revolutionary area, and ponder the ethical dimensions that accompany such progress.\n",
            "\n",
            "#### Pushing the Bounds of Communication: AI’s Linguistic Leap\n",
            "\n",
            "Your last conversation with Siri or Alexa likely felt more natural than ever before—and with good reason. They're powered by the latest developments in natural language processing (NLP). Imagine machines that don't just comprehend words but grasp context, irony, and ethos, transforming how they assist and engage us. This breakthrough stems from sophisticated neural networks and the integration of vast linguistic databases. Now, AI can decode accents, social cues, and local vernaculars, making for an interaction that’s almost indistinguishably human.\n",
            "\n",
            "But let’s go deeper. Imagine a scenario where an AI assistant helps a child with their homework, shifting its language and explanations to match the child's developmental stage. It's not just a future concept; projects like these are underway and represent the profound potential of customized AI in education.\n",
            "\n",
            "#### The Heart of AI Innovation: Revolutionizing Healthcare\n",
            "\n",
            "Healthcare is experiencing a seismic shift due to AI's diagnostic and prognostic capabilities. AI systems aren't just predicting outcomes; they're recommending personalized treatments that could mean the difference between life and death. Let’s take a closer look at one area: AI in cancer detection. Algorithms can now analyze pathology images, catching signs of cancer at its earliest, most treatable stages with an accuracy that rivals human pathologists.\n",
            "\n",
            "An anecdote that illustrates this comes from a recent study where AI was used to pore over mammogram images. The algorithm detected subtle patterns that humans couldn’t, pinpointing early signs of breast cancer with a staggering level of accuracy. This isn't replacing the human touch; it's amplifying it, providing healthcare professionals with a powerful ally in the quest for better patient outcomes.\n",
            "\n",
            "#### Intertwined with Our Daily Existence: AI in Personal Tech\n",
            "\n",
            "Beyond the realms of technical wizardry, these smart technologies are infiltrating our everyday gadgets, making personal tech smarter and more intuitive. Your smartphone, quite possibly, is silently learning from your behaviors to optimize its functions, whether it's managing power consumption more efficiently or suggesting the quickest route during your daily commute.\n",
            "\n",
            "Consider smart homes where AI-controlled systems manage everything from lighting to security, learning from daily patterns to run your home more efficiently. There's also the humble example of e-commerce, where AI now predicts our shopping behavior, sometimes knowing what we need before we do!\n",
            "\n",
            "#### Navigating the Complex Web of AI Ethics\n",
            "\n",
            "The conversation isn’t complete without addressing the moral quandaries AI brings to the fore. There is no escape from deliberations on AI's role in data privacy, the potential for embedded biases, and the implications of decisions made without human intervention. Take, for instance, facial recognition technology. While it has its benefits, there are genuine concerns about surveillance and racial profiling, evidenced in the pushback from civil liberties groups and recent moratoriums placed in various cities.\n",
            "\n",
            "Encouragingly, there's a growing movement towards 'ethical AI'. A powerful example is the establishment of ethics boards within AI companies, aimed at ensuring technologies are developed and deployed responsibly. The European Union's ethics guidelines for trustworthy AI is another formidable step toward blending innovation with humanity's best values.\n",
            "\n",
            "#### Looking to the AI Horizon\n",
            "\n",
            "As we envision a future permeated by AI, we can't help but be amazed by the doors it's poised to open. From environmental conservation efforts using AI to track and protect endangered species, to the prospect of smart cities where every element of urban life is enhanced by AI, the possibilities are as vast as our imagination. \n",
            "\n",
            "In closing, AI's recent developments aren’t just steps; they're quantum leaps toward a future where technology and humans coalesce more seamlessly than ever before. By marrying our human ingenuity with AI's potential—while navigating its challenges with wisdom—we're setting the stage for a world where technology amplifies the best of what we can achieve together.\n",
            "\n",
            "AI is not just an evolution; it's the beginning of a renaissance, a new chapter of human endeavor. As we continue to weave the AI narrative into our societal tapestry, we must do so with mindful consideration of its profound impact on our collective journey. The future of AI is here, and it's our shared adventure to navigate it responsibly.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQEOBen4sv_q",
        "outputId": "8c9568fb-6c97-4521-89f2-0a233ac6feb4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.5)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "import autogen\n",
        "from autogen import AssistantAgent\n",
        "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
        "from chromadb.utils import embedding_functions"
      ],
      "metadata": {
        "id": "3lpHccKssrrV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = AssistantAgent(\n",
        "    name=\"assistant\",\n",
        "    system_message=\"You are a helpful assistant.\",\n",
        "    llm_config={\n",
        "        \"timeout\": 600,\n",
        "        \"cache_seed\": 42,\n",
        "        \"config_list\": config_list,\n",
        "    },\n",
        ")\n",
        "ragproxyagent = RetrieveUserProxyAgent(\n",
        "    name=\"ragproxyagent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=3,\n",
        "    retrieve_config={\n",
        "        \"task\": \"code\",\n",
        "        \"docs_path\": [\n",
        "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md\",\n",
        "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md\",\n",
        "            os.path.join(os.path.abspath(\"\"), \"..\", \"website\", \"docs\"),\n",
        "        ],\n",
        "        \"custom_text_types\": [\"mdx\"],\n",
        "        \"chunk_token_size\": 2000,\n",
        "        \"model\": config_list[0][\"model\"],\n",
        "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
        "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
        "        \"get_or_create\": False,  # set to False if you don't want to reuse an existing collection, but you'll need to remove the collection manually\n",
        "    },\n",
        "    code_execution_config=False,  # set to False if you don't want to execute the code\n",
        ")"
      ],
      "metadata": {
        "id": "n9lC7sqZuCGR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\"\n",
        "ragproxyagent.initiate_chat(\n",
        "    assistant, message=ragproxyagent.message_generator, problem=code_problem, search_string=\"spark\"\n",
        ")\n",
        " # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain \"spark\"."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYlN1vW-udwg",
        "outputId": "61307952-6a05-4421-e222-de6a8bc018fd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to create collection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.retrieve_utils:File /content/../website/docs does not exist. Skipping.\n",
            "2025-01-04 14:37:50,192 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - Found 2 chunks.\n",
            "2025-01-04 14:37:50,201 - autogen.agentchat.contrib.vectordb.chromadb - INFO - No content embedding is provided. Will use the VectorDB's embedding function to generate the content embedding.\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 20 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorDB returns doc_ids:  [['bdfbc921']]\n",
            "Adding content of doc bdfbc921 to context.\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "You're a retrieve augmented coding assistant. You answer user's questions based on your own knowledge and the\n",
            "context provided by the user.\n",
            "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
            "For code generation, you must obey the following rules:\n",
            "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
            "Rule 2. You must follow the formats below to write your code:\n",
            "```language\n",
            "# your code\n",
            "```\n",
            "\n",
            "User's question is: How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\n",
            "\n",
            "Context is: # Integrate - Spark\n",
            "\n",
            "FLAML has integrated Spark for distributed training. There are two main aspects of integration with Spark:\n",
            "\n",
            "- Use Spark ML estimators for AutoML.\n",
            "- Use Spark to run training in parallel spark jobs.\n",
            "\n",
            "## Spark ML Estimators\n",
            "\n",
            "FLAML integrates estimators based on Spark ML models. These models are trained in parallel using Spark, so we called them Spark estimators. To use these models, you first need to organize your data in the required format.\n",
            "\n",
            "### Data\n",
            "\n",
            "For Spark estimators, AutoML only consumes Spark data. FLAML provides a convenient function `to_pandas_on_spark` in the `flaml.automl.spark.utils` module to convert your data into a pandas-on-spark (`pyspark.pandas`) dataframe/series, which Spark estimators require.\n",
            "\n",
            "This utility function takes data in the form of a `pandas.Dataframe` or `pyspark.sql.Dataframe` and converts it into a pandas-on-spark dataframe. It also takes `pandas.Series` or `pyspark.sql.Dataframe` and converts it into a [pandas-on-spark](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html) series. If you pass in a `pyspark.pandas.Dataframe`, it will not make any changes.\n",
            "\n",
            "This function also accepts optional arguments `index_col` and `default_index_type`.\n",
            "\n",
            "- `index_col` is the column name to use as the index, default is None.\n",
            "- `default_index_type` is the default index type, default is \"distributed-sequence\". More info about default index type could be found on Spark official [documentation](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/options.html#default-index-type)\n",
            "\n",
            "Here is an example code snippet for Spark Data:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "from flaml.automl.spark.utils import to_pandas_on_spark\n",
            "\n",
            "# Creating a dictionary\n",
            "data = {\n",
            "    \"Square_Feet\": [800, 1200, 1800, 1500, 850],\n",
            "    \"Age_Years\": [20, 15, 10, 7, 25],\n",
            "    \"Price\": [100000, 200000, 300000, 240000, 120000],\n",
            "}\n",
            "\n",
            "# Creating a pandas DataFrame\n",
            "dataframe = pd.DataFrame(data)\n",
            "label = \"Price\"\n",
            "\n",
            "# Convert to pandas-on-spark dataframe\n",
            "psdf = to_pandas_on_spark(dataframe)\n",
            "```\n",
            "\n",
            "To use Spark ML models you need to format your data appropriately. Specifically, use [`VectorAssembler`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html) to merge all feature columns into a single vector column.\n",
            "\n",
            "Here is an example of how to use it:\n",
            "\n",
            "```python\n",
            "from pyspark.ml.feature import VectorAssembler\n",
            "\n",
            "columns = psdf.columns\n",
            "feature_cols = [col for col in columns if col != label]\n",
            "featurizer = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
            "psdf = featurizer.transform(psdf.to_spark(index_col=\"index\"))[\"index\", \"features\"]\n",
            "```\n",
            "\n",
            "Later in conducting the experiment, use your pandas-on-spark data like non-spark data and pass them using `X_train, y_train` or `dataframe, label`.\n",
            "\n",
            "### Estimators\n",
            "\n",
            "#### Model List\n",
            "\n",
            "- `lgbm_spark`: The class for fine-tuning Spark version LightGBM models, using [SynapseML](https://microsoft.github.io/SynapseML/docs/features/lightgbm/about/) API.\n",
            "\n",
            "#### Usage\n",
            "\n",
            "First, prepare your data in the required format as described in the previous section.\n",
            "\n",
            "By including the models you intend to try in the `estimators_list` argument to `flaml.automl`, FLAML will start trying configurations for these models. If your input is Spark data, FLAML will also use estimators with the `_spark` postfix by default, even if you haven't specified them.\n",
            "\n",
            "Here is an example code snippet using SparkML models in AutoML:\n",
            "\n",
            "```python\n",
            "import flaml\n",
            "\n",
            "# prepare your data in pandas-on-spark format as we previously mentioned\n",
            "\n",
            "automl = flaml.AutoML()\n",
            "settings = {\n",
            "    \"time_budget\": 30,\n",
            "    \"metric\": \"r2\",\n",
            "    \"estimator_list\": [\"lgbm_spark\"],  # this setting is optional\n",
            "    \"task\": \"regression\",\n",
            "}\n",
            "\n",
            "automl.fit(\n",
            "    dataframe=psdf,\n",
            "    label=label,\n",
            "    **settings,\n",
            ")\n",
            "```\n",
            "\n",
            "[Link to notebook](https://github.com/microsoft/FLAML/blob/main/notebook/automl_bankrupt_synapseml.ipynb) | [Open in colab](https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/automl_bankrupt_synapseml.ipynb)\n",
            "\n",
            "## Parallel Spark Jobs\n",
            "\n",
            "You can activate Spark as the parallel backend during parallel tuning in both [AutoML](/docs/Use-Cases/Task-Oriented-AutoML#parallel-tuning) and [Hyperparameter Tuning](/docs/Use-Cases/Tune-User-Defined-Function#parallel-tuning), by setting the `use_spark` to `true`. FLAML will dispatch your job to the distributed Spark backend using [`joblib-spark`](https://github.com/joblib/joblib-spark).\n",
            "\n",
            "Please note that you should not set `use_spark` to `true` when applying AutoML and Tuning for Spark Data. This is because only SparkML models will be used for Spark Data in AutoML and Tuning. As SparkML models run in parallel, there is no need to distribute them with `use_spark` again.\n",
            "\n",
            "All the Spark-related arguments are stated below. These arguments are available in both Hyperparameter Tuning and AutoML:\n",
            "\n",
            "- `use_spark`: boolean, default=False | Whether to use spark to run the training in parallel spark jobs. This can be used to accelerate training on large models and large datasets, but will incur more overhead in time and thus slow down training in some cases. GPU training is not supported yet when use_spark is True. For Spark clusters, by default, we will launch one trial per executor. However, sometimes we want to launch more trials than the number of executors (e.g., local mode). In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override the detected `num_executors`. The final number of concurrent trials will be the minimum of `n_concurrent_trials` and `num_executors`.\n",
            "- `n_concurrent_trials`: int, default=1 | The number of concurrent trials. When n_concurrent_trials > 1, FLAML performes parallel tuning.\n",
            "- `force_cancel`: boolean, default=False | Whether to forcely cancel Spark jobs if the search time exceeded the time budget. Spark jobs include parallel tuning jobs and Spark-based model training jobs.\n",
            "\n",
            "An example code snippet for using parallel Spark jobs:\n",
            "\n",
            "```python\n",
            "import flaml\n",
            "\n",
            "automl_experiment = flaml.AutoML()\n",
            "automl_settings = {\n",
            "    \"time_budget\": 30,\n",
            "    \"metric\": \"r2\",\n",
            "    \"task\": \"regression\",\n",
            "    \"n_concurrent_trials\": 2,\n",
            "    \"use_spark\": True,\n",
            "    \"force_cancel\": True,  # Activating the force_cancel option can immediately halt Spark jobs once they exceed the allocated time_budget.\n",
            "}\n",
            "\n",
            "automl.fit(\n",
            "    dataframe=dataframe,\n",
            "    label=label,\n",
            "    **automl_settings,\n",
            ")\n",
            "```\n",
            "\n",
            "[Link to notebook](https://github.com/microsoft/FLAML/blob/main/notebook/integrate_spark.ipynb) | [Open in colab](https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/integrate_spark.ipynb)\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "Based on the provided context about FLAML's integration with Spark for distributed training, here is how you can use FLAML to perform a classification task and use Spark to do parallel training with a 30 second train time budget and force cancellation of jobs if the time limit is reached:\n",
            "\n",
            "```python\n",
            "import flaml\n",
            "from flaml.automl.spark.utils import to_pandas_on_spark\n",
            "from pyspark.ml.feature import VectorAssembler\n",
            "import pandas as pd\n",
            "\n",
            "# Assume `dataframe` is your input pandas DataFrame for the classification task and `label` is the name of the target column.\n",
            "# Here is a mock-up of your input data:\n",
            "data = {\n",
            "    \"feature1\": [0, 1, 2, 3, 4],\n",
            "    \"feature2\": [5, 6, 7, 8, 9],\n",
            "    \"target\": [1, 0, 1, 0, 1],  # Binary classification\n",
            "}\n",
            "dataframe = pd.DataFrame(data)\n",
            "label = \"target\"\n",
            "\n",
            "# Step 1: Convert the pandas DataFrame to a pandas-on-spark DataFrame.\n",
            "psdf = to_pandas_on_spark(dataframe)\n",
            "\n",
            "# Step 2: Use VectorAssembler to merge all feature columns into a single vector column.\n",
            "feature_cols = [col for col in psdf.columns if col != label]\n",
            "featurizer = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
            "psdf = featurizer.transform(psdf.to_spark(index_col=\"index\"))[\"index\", \"features\", label]\n",
            "\n",
            "# Step 3: Create an AutoML instance and specify the classification task.\n",
            "automl = flaml.AutoML()\n",
            "\n",
            "# Step 4: Define settings for the AutoML training.\n",
            "settings = {\n",
            "    \"time_budget\": 30,  # 30 second train time budget\n",
            "    \"metric\": \"accuracy\",  # Use an appropriate metric for classification\n",
            "    \"estimator_list\": [\"lgbm_spark\"],  # Using Spark version of LightGBM model\n",
            "    \"task\": \"classification\",\n",
            "    \"n_concurrent_trials\": 2,  # Number of parallel trials\n",
            "    \"use_spark\": True,  # Use Spark for distributed training\n",
            "    \"force_cancel\": True,  # Force cancel jobs if time limit is reached\n",
            "}\n",
            "\n",
            "# Step 5: Start the AutoML training process.\n",
            "automl.fit(\n",
            "    dataframe=psdf.to_pandas(index_col=\"index\"),\n",
            "    label=label,\n",
            "    **settings\n",
            ")\n",
            "```\n",
            "\n",
            "Please replace the mock-up data with your actual data and select an appropriate metric and estimators for your specific classification task.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to ragproxyagent):\n",
            "\n",
            "UPDATE CONTEXT\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Updating context and resetting conversation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 60 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorDB returns doc_ids:  [['bdfbc921']]\n",
            "No more context, will terminate.\n",
            "ragproxyagent (to assistant):\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'TERMINATE', 'role': 'assistant', 'name': 'ragproxyagent'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0.05748, 'gpt-4-1106-preview': {'cost': 0.05748, 'prompt_tokens': 4125, 'completion_tokens': 541, 'total_tokens': 4666}}, 'usage_excluding_cached_inference': {'total_cost': 0.05748, 'gpt-4-1106-preview': {'cost': 0.05748, 'prompt_tokens': 4125, 'completion_tokens': 541, 'total_tokens': 4666}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JOsJWwvivcco",
        "outputId": "7266e47b-8955-43a0-ba0a-70ed57aed702"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.6.6.post1-cp38-abi3-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.47.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (5.29.2)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.115.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.11.10)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.57.4)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.34.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.10.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (11.0.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.9 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.9-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar>=0.1.6 (from vllm)\n",
            "  Downloading xgrammar-0.1.8-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.16.1)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf==0.10.0 (from vllm)\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.5.0)\n",
            "Collecting mistral_common>=1.5.0 (from mistral_common[opencv]>=1.5.0->vllm)\n",
            "  Downloading mistral_common-1.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n",
            "Collecting compressed-tensors==0.8.1 (from vllm)\n",
            "  Downloading compressed_tensors-0.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from vllm) (3.1.0)\n",
            "Collecting ray>=2.9 (from ray[default]>=2.9->vllm)\n",
            "  Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting nvidia-ml-py>=12.560.30 (from vllm)\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.1+cu121)\n",
            "Collecting xformers==0.0.28.post3 (from vllm)\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from depyf==0.18.0->vllm)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (3.1.4)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (0.35.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20241001-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.41.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
            "Collecting pillow (from vllm)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.10.0.84)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (2.27.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (8.1.7)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.5.0)\n",
            "Collecting aiohttp-cors (from ray[default]>=2.9->vllm)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default]>=2.9->vllm)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default]>=2.9->vllm)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default]>=2.9->vllm)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.9->vllm) (7.1.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default]>=2.9->vllm)\n",
            "  Downloading virtualenv-20.28.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]>=2.9->vllm) (1.68.1)\n",
            "Collecting memray (from ray[default]>=2.9->vllm)\n",
            "  Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.4)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (24.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2024.12.14)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.2->vllm) (0.4.5)\n",
            "Collecting pybind11 (from xgrammar>=0.1.6->vllm)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from xgrammar>=0.1.6->vllm) (8.3.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (14.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.52.0->vllm) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.22.3)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: rich>=11.2.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default]>=2.9->vllm) (13.9.4)\n",
            "Collecting textual>=0.41.0 (from memray->ray[default]>=2.9->vllm)\n",
            "  Downloading textual-1.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]>=2.9->vllm)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]>=2.9->vllm) (1.17.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]>=2.9->vllm) (2.19.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (2.2.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default]>=2.9->vllm) (1.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.25.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (2.27.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]>=2.9->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]>=2.9->vllm) (2.18.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]>=2.9->vllm) (0.1.2)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]>=2.9->vllm) (0.4.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]>=2.9->vllm) (2.0.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default]>=2.9->vllm) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.6.1)\n",
            "Downloading vllm-0.6.6.post1-cp38-abi3-manylinux1_x86_64.whl (201.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.8.1-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.9-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl (66.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.8-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (339 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.8/339.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.5/367.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl (9.9 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.28.1-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading airportsdata-20241001-py3-none-any.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading textual-1.0.0-py3-none-any.whl (660 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.5/660.5 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-spy, opencensus-context, nvidia-ml-py, distlib, colorful, blake3, virtualenv, pycountry, pybind11, pillow, partial-json-parser, msgspec, lark, interegular, gguf, dill, astor, airportsdata, tiktoken, depyf, xformers, prometheus-fastapi-instrumentator, lm-format-enforcer, textual, ray, outlines_core, opencensus, mistral_common, aiohttp-cors, xgrammar, outlines, memray, compressed-tensors, vllm\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.8.0\n",
            "    Uninstalling tiktoken-0.8.0:\n",
            "      Successfully uninstalled tiktoken-0.8.0\n",
            "Successfully installed aiohttp-cors-0.7.0 airportsdata-20241001 astor-0.8.1 blake3-1.0.1 colorful-0.5.6 compressed-tensors-0.8.1 depyf-0.18.0 dill-0.3.9 distlib-0.3.9 gguf-0.10.0 interegular-0.3.3 lark-1.2.2 lm-format-enforcer-0.10.9 memray-1.15.0 mistral_common-1.5.1 msgspec-0.19.0 nvidia-ml-py-12.560.30 opencensus-0.11.4 opencensus-context-0.1.3 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post4 pillow-10.4.0 prometheus-fastapi-instrumentator-7.0.0 py-spy-0.4.0 pybind11-2.13.6 pycountry-24.6.1 ray-2.40.0 textual-1.0.0 tiktoken-0.7.0 virtualenv-20.28.1 vllm-0.6.6.post1 xformers-0.0.28.post3 xgrammar-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "tiktoken",
                  "tiktoken_ext"
                ]
              },
              "id": "84d2553a765e478c852af2efdfc5ed45"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5MchT4z0DJy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}